#!/usr/bin/env python3
"""
Plot a zoomed-in TPS/P99 comparison for local vs cross NUMA runs.
This keeps only the top portion of the y-axis so small differences are clearer
and annotates the delta between local and cross.
"""

import argparse
import csv
import re
import statistics
import sys
from pathlib import Path
from typing import Optional

try:
    import matplotlib.pyplot as plt
except ImportError as exc:  # pragma: no cover
    sys.stderr.write("matplotlib is required. Install with: pip install matplotlib\n")
    raise


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Plot a zoomed local vs cross NUMA comparison (TPS/P99)."
    )
    parser.add_argument(
        "--csv",
        default="sysbench_results/oltp_rw_local_numa_cross.csv",
        help="CSV file generated by run_sysbench_oltp_rw_local_numa_cross.sh",
    )
    parser.add_argument(
        "--output",
        default="sysbench_results/oltp_rw_local_numa_cross_compare_zoom.png",
        help="Output image path (PNG)",
    )
    parser.add_argument(
        "--pad-ratio",
        type=float,
        default=0.25,
        help="Extra headroom (fraction of value span) for annotations.",
    )
    return parser.parse_args()


def classify_row(row: dict) -> Optional[str]:
    cpu = (row.get("mysql_cpu_node") or "").strip()
    mem = (row.get("mysql_mem_node") or "").strip()
    if cpu and mem:
        return "local" if cpu == mem else "cross"

    profile = (row.get("numa_profile") or "").strip()
    match = re.match(r"^node(\d+)_mem(\d+)$", profile)
    if match:
        return "local" if match.group(1) == match.group(2) else "cross"
    return None


def load_data(csv_path: Path):
    if not csv_path.exists():
        sys.stderr.write(f"CSV not found: {csv_path}\n")
        sys.exit(1)

    data = {"local": {"tps": [], "p99": []}, "cross": {"tps": [], "p99": []}}
    with csv_path.open(newline="") as f:
        reader = csv.DictReader(f)
        required = {"status", "tps", "p99_latency_ms"}
        missing = required - set(reader.fieldnames or [])
        if missing:
            sys.stderr.write(f"CSV missing columns: {', '.join(sorted(missing))}\n")
            sys.exit(1)

        for row in reader:
            if row.get("status") != "ok":
                continue
            bucket = classify_row(row)
            if not bucket:
                continue
            try:
                tps = float(row["tps"])
                p99 = float(row["p99_latency_ms"])
            except (TypeError, ValueError):
                continue
            data[bucket]["tps"].append(tps)
            data[bucket]["p99"].append(p99)

    if not (data["local"]["tps"] or data["cross"]["tps"]):
        sys.stderr.write("No usable rows (need status=ok with numeric TPS/P99).\n")
        sys.exit(1)

    return data


def stats(values):
    mean = statistics.mean(values)
    std = statistics.stdev(values) if len(values) > 1 else 0.0
    return mean, std


def calc_ylim(means, errs, pad_ratio):
    min_mean = min(means)
    max_mean = max(means)
    span = max(max_mean - min_mean, (max_mean or 1.0) * 0.01)
    pad = span * pad_ratio + (max(errs) if errs else 0) * 1.1
    lower = max(min_mean - pad, 0)
    upper = max_mean + pad
    return lower, upper


def annotate_gap(ax, labels, means, color="#d62728"):
    if len(means) < 2:
        return

    min_idx = min(range(len(means)), key=means.__getitem__)
    max_idx = max(range(len(means)), key=means.__getitem__)
    min_val, max_val = means[min_idx], means[max_idx]
    diff = max_val - min_val
    pct = diff / min_val * 100 if min_val else float("inf")

    ylim = ax.get_ylim()
    height = ylim[1] - ylim[0]
    y = ylim[1] - height * 0.15

    ax.annotate(
        "",
        xy=(max_idx, y),
        xytext=(min_idx, y),
        arrowprops=dict(arrowstyle="<->", color=color, lw=2.0),
    )
    ax.text(
        (min_idx + max_idx) / 2,
        y,
        f"Î” {diff:.2f} ({pct:+.2f}%)",
        ha="center",
        va="bottom",
        color=color,
        fontweight="bold",
        bbox=dict(boxstyle="round,pad=0.3", fc="white", ec=color, lw=0.8),
    )


def plot_zoomed(data, output_path: Path, pad_ratio: float):
    order = [k for k in ("local", "cross") if data[k]["tps"]]
    labels = [f"{k} (n={len(data[k]['tps'])})" for k in order]

    tps_means = [stats(data[k]["tps"])[0] for k in order]
    tps_err = [stats(data[k]["tps"])[1] for k in order]
    p99_means = [stats(data[k]["p99"])[0] for k in order]
    p99_err = [stats(data[k]["p99"])[1] for k in order]

    fig, axes = plt.subplots(1, 2, figsize=(10, 4))
    colors = ["#2ca02c" if k == "local" else "#d62728" for k in order]

    bars_tps = axes[0].bar(labels, tps_means, yerr=tps_err, color=colors, capsize=6)
    axes[0].set_ylabel("Transactions per second (TPS)")
    axes[0].set_title("TPS (zoomed)")
    axes[0].grid(axis="y", linestyle="--", alpha=0.35)
    axes[0].set_ylim(*calc_ylim(tps_means, tps_err, pad_ratio))
    axes[0].bar_label(bars_tps, fmt="%.2f", padding=3, fontsize=9)
    annotate_gap(axes[0], labels, tps_means)

    bars_p99 = axes[1].bar(labels, p99_means, yerr=p99_err, color=colors, capsize=6)
    axes[1].set_ylabel("P99 latency (ms)")
    axes[1].set_title("P99 latency (zoomed)")
    axes[1].grid(axis="y", linestyle="--", alpha=0.35)
    axes[1].set_ylim(*calc_ylim(p99_means, p99_err, pad_ratio))
    axes[1].bar_label(bars_p99, fmt="%.2f", padding=3, fontsize=9)
    annotate_gap(axes[1], labels, p99_means)

    fig.suptitle("oltp_read_write NUMA (zoomed): local vs cross")
    fig.tight_layout(rect=[0, 0, 1, 0.94])

    output_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(output_path, dpi=180)
    print(f"Saved zoomed plot: {output_path}")


def main():
    args = parse_args()
    data = load_data(Path(args.csv))
    plot_zoomed(data, Path(args.output), args.pad_ratio)


if __name__ == "__main__":
    main()
